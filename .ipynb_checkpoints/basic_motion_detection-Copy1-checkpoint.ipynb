{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ZahraEk/OpenCV-Course/blob/main/basic_motion_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GOXNfcBH-QWW"
   },
   "source": [
    "import Required libraries :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RvBj8L2i-Uib"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVnSgJThDDk7"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Implementing a basic background subtractor**\n",
    "\n",
    "To implement a basic background subtractor, let's take the following approach:\n",
    "1. Start capturing frames from a camera.\n",
    "2. Discard nine frames so that the camera has time to properly adjust its autoexposure to suit the lighting conditions in the scene.\n",
    "3. Take the 10th frame, convert it to grayscale, blur it, and use this blurred image as the reference image of the background.\n",
    "4. For each subsequent frame, blur the frame, convert it to grayscale, and compute the absolute difference between this blurred frame and the reference image of the background. Perform thresholding, smoothing, and contour detection on the differenced image. Draw and show the bounding boxes of the major contours.\n",
    "\n",
    "More details in :[ðŸ“„OpenCV_Course.pdf](https://github.com/ZahraEk/OpenCV-Course/blob/main/OpenCV_Course.pdf) | pages 5-8\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qXUAskISgLJe",
    "outputId": "f74389b1-8367-4cac-da22-3cbb09dadd68"
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m         exit(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Convert the 10th frame to grayscale and apply Gaussian blur\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m gray_background \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m     17\u001b[0m gray_background \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mGaussianBlur(gray_background, (BLUR_RADIUS, BLUR_RADIUS), \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Show gray background\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "# Define the blur radius and kernel sizes for erosion and dilation\n",
    "BLUR_RADIUS = 21\n",
    "erode_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "dilate_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9))\n",
    "\n",
    "# Open the video file for reading\n",
    "cap = cv2.VideoCapture(\"D:\\OpenCV_Course\\videos\\pedestrians.avi\")\n",
    "\n",
    "# Capture 10 frames to allow the camera's autoexposure to adjust.\n",
    "for i in range(10):\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        exit(1)\n",
    "\n",
    "# Convert the 10th frame to grayscale and apply Gaussian blur\n",
    "gray_background = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "gray_background = cv2.GaussianBlur(gray_background, (BLUR_RADIUS, BLUR_RADIUS), 0)\n",
    "\n",
    "# Show gray background\n",
    "plt.figure(figsize = (4,4))\n",
    "plt.imshow(gray_background, cmap='gray')\n",
    "plt.title('Gray background')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Display the first 5 frames\n",
    "for i in range(5):\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # Convert the current frame to grayscale and apply Gaussian blur\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (BLUR_RADIUS, BLUR_RADIUS), 0)\n",
    "\n",
    "    # Calculate the absolute difference between the background and the current frame\n",
    "    diff = cv2.absdiff(gray_background, gray_frame)\n",
    "\n",
    "    # Apply thresholding to create a binary image\n",
    "    _, thresh = cv2.threshold(diff, 40, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Apply morphological erosion and dilation to smoothen the thresholded image\n",
    "    cv2.erode(thresh, erode_kernel, thresh, iterations=2)\n",
    "    cv2.dilate(thresh, dilate_kernel, thresh, iterations=2)\n",
    "\n",
    "    # Find contours of objects in the thresholded image\n",
    "    contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Loop through detected contours and draw bounding rectangles for large ones\n",
    "    for c in contours:\n",
    "        if cv2.contourArea(c) > 4000:\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "\n",
    "    # Create a subplot for each image and display it\n",
    "    print(f\"\\nFrame {i+1} :\\n\")\n",
    "    f, subplt = plt.subplots(1,3, figsize=(16,12))\n",
    "\n",
    "    subplt[0].imshow(diff, cmap='gray')\n",
    "    subplt[0].set_title('Difference')\n",
    "    subplt[0].axis('off')\n",
    "\n",
    "    subplt[1].imshow(thresh, cmap='gray')\n",
    "    subplt[1].set_title('Thresholded')\n",
    "    subplt[1].axis('off')\n",
    "\n",
    "    subplt[2].imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    subplt[2].set_title('Detection')\n",
    "    subplt[2].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Release the video capture object and close OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pj1JqS7f-m1p"
   },
   "source": [
    "\n",
    "> Result in video form : [BasicDetection_pedestrians.avi](https://drive.google.com/file/d/13eDrE66dNExygCrOwXnnIr8ermk-m4FV/view?usp=sharing)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMQm8p0HiTpERe62neZPwE8",
   "include_colab_link": true,
   "mount_file_id": "1_8yOpd4sgH_T9skZmI2dTxlaUGqxHk62",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
