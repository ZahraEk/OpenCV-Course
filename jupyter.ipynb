{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ZahraEk/OpenCV-Course/blob/main/basic_motion_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GOXNfcBH-QWW"
   },
   "source": [
    "import Required libraries :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RvBj8L2i-Uib"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"videos\"):\n",
    "    !git clone https://github.com/ZahraEk/OpenCV-Course.git\n",
    "    !mv OpenCV-Course/videos ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVnSgJThDDk7"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Implementing a basic background subtractor**\n",
    "\n",
    "To implement a basic background subtractor, let's take the following approach:\n",
    "1. Start capturing frames from a camera.\n",
    "2. Discard nine frames so that the camera has time to properly adjust its autoexposure to suit the lighting conditions in the scene.\n",
    "3. Take the 10th frame, convert it to grayscale, blur it, and use this blurred image as the reference image of the background.\n",
    "4. For each subsequent frame, blur the frame, convert it to grayscale, and compute the absolute difference between this blurred frame and the reference image of the background. Perform thresholding, smoothing, and contour detection on the differenced image. Draw and show the bounding boxes of the major contours.\n",
    "\n",
    "More details in :[ðŸ“„OpenCV_Course.pdf](https://github.com/ZahraEk/OpenCV-Course/blob/main/OpenCV_Course.pdf) | pages 5-8\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qXUAskISgLJe",
    "outputId": "f74389b1-8367-4cac-da22-3cbb09dadd68"
   },
   "outputs": [],
   "source": [
    "# Define the blur radius and kernel sizes for erosion and dilation\n",
    "BLUR_RADIUS = 21\n",
    "erode_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "dilate_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9))\n",
    "\n",
    "# Open the video file for reading\n",
    "cap = cv2.VideoCapture(\"videos\\pedestrians.avi\")\n",
    "\n",
    "# Capture 10 frames to allow the camera's autoexposure to adjust.\n",
    "for i in range(10):\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        exit(1)\n",
    "\n",
    "# Convert the 10th frame to grayscale and apply Gaussian blur\n",
    "gray_background = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "gray_background = cv2.GaussianBlur(gray_background, (BLUR_RADIUS, BLUR_RADIUS), 0)\n",
    "\n",
    "\n",
    "# Capture a frame from the camera\n",
    "success, frame = cap.read()\n",
    "while success:\n",
    "\n",
    "    # Convert the current frame to grayscale and apply Gaussian blur\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (BLUR_RADIUS, BLUR_RADIUS), 0)\n",
    "\n",
    "    # Calculate the absolute difference between the background and the current frame\n",
    "    diff = cv2.absdiff(gray_background, gray_frame)\n",
    "\n",
    "    # Apply thresholding to create a binary image\n",
    "    _, thresh = cv2.threshold(diff, 40, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Apply morphological erosion and dilation to smoothen the thresholded image\n",
    "    cv2.erode(thresh, erode_kernel, thresh, iterations=2)\n",
    "    cv2.dilate(thresh, dilate_kernel, thresh, iterations=2)\n",
    "\n",
    "    # Find contours of objects in the thresholded image\n",
    "    contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Loop through detected contours and draw bounding rectangles for large ones\n",
    "    for c in contours:\n",
    "        if cv2.contourArea(c) > 4000:\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow('Diff', diff)\n",
    "    cv2.imshow('Thresh', thresh)\n",
    "    cv2.imshow('Detection', frame)\n",
    "\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:  # Escape\n",
    "        break\n",
    "\n",
    "    # Capture a frame from the camera\n",
    "    success, frame = cap.read()\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pj1JqS7f-m1p"
   },
   "source": [
    "\n",
    "> Result in video form : [BasicDetection_pedestrians.avi](https://drive.google.com/file/d/13eDrE66dNExygCrOwXnnIr8ermk-m4FV/view?usp=sharing)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMQm8p0HiTpERe62neZPwE8",
   "include_colab_link": true,
   "mount_file_id": "1_8yOpd4sgH_T9skZmI2dTxlaUGqxHk62",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
